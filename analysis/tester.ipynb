{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "sys.path.append(\"../src/Metamodel/\")\n",
    "\n",
    "from utils import EarlyStopping\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from data.dataloader import create_train_val_loader\n",
    "\n",
    "from models.depthwiseNet import DepthNet\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, auc, roc_auc_score, f1_score, classification_report\n",
    "from torchmetrics.classification import MulticlassAUROC\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "import random\n",
    "\n",
    "# from pytorchtools import EarlyStopping\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "np.random.seed(0)\n",
    "cudnn.benchmark = False\n",
    "cudnn.deterministic = True\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.cuda.manual_seed_all(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPATH = \"../data/new\"\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DepthNet(lengths=30, patch_size=30, in_chans=2, embed_dim=256, norm_layer=None, output_dim=3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_results_meta = []\n",
    "\n",
    "# MODELPATH = f\"../singlelog/total_3class.pt\"\n",
    "MODELPATH = \"../src/Metamodel/log/best_model_t1t2.pt\"\n",
    "#MODELPATH = \"../src/Metamodel/log/best_model_cg.pt\"\n",
    "pretrained = torch.load(MODELPATH, map_location=device)\n",
    "model.load_state_dict(pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightedType = \"macro\"\n",
    "batch_size = 256\n",
    "auroc = MulticlassAUROC(num_classes=3, average=weightedType).to(device)\n",
    "\n",
    "test_result_dic = {\"loss\": [], \"acc\": [], \"f1\": [], \"auc\": [], \"confusion_matrix\": []}\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loss = 0\n",
    "\n",
    "for i in range(10):\n",
    "    client_num = i+1\n",
    "    print(f\"Client {client_num} Test\")\n",
    "    PATH = os.path.join(\"../data/new\", f\"c{i+1}_data.csv\")\n",
    "    \n",
    "    generator = torch.Generator()\n",
    "    generator.manual_seed(0)\n",
    "    \n",
    "    train_set, _ = create_train_val_loader(DATAPATH, batch_size, length=30,\n",
    "                                                    meta_train_client_idx_lst=[client_num], FLtrain=True)\n",
    "    train_data, test_data = torch.utils.data.random_split(train_set,\n",
    "                                                            [int(len(train_set)*0.8),\n",
    "                                                            len(train_set)-int(len(train_set)*0.8)],\n",
    "                                                            generator=generator)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "            train_data, batch_size=32, shuffle=True, drop_last=False\n",
    "        )\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "            test_data, batch_size=32, shuffle=True, drop_last=False\n",
    "        )\n",
    "    \n",
    "    test_pred = []\n",
    "    test_real = []\n",
    "    test_proba = []\n",
    "\n",
    "    correct = 0\n",
    "\n",
    "    test_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        for data in test_loader:\n",
    "            x_data, stage = data[0].to(device), data[1].to(device)\n",
    "            \n",
    "            # pred_value, _ = model(x_data)\n",
    "            pred_value, _ = model(x_data)\n",
    "            pred = torch.argmax(pred_value, dim=1)\n",
    "            pred_proba = torch.sigmoid(pred_value)\n",
    "\n",
    "            correct += torch.sum(pred==stage).item()\n",
    "\n",
    "            test_pred.extend(pred.detach().cpu().numpy())\n",
    "            test_real.extend(stage.detach().cpu().numpy())\n",
    "            test_proba.extend(pred_proba.detach().cpu().numpy())\n",
    "\n",
    "            loss = criterion(pred_value, stage)\n",
    "            test_loss += loss.item()\n",
    "        \n",
    "        auc = auroc(torch.tensor(test_proba), torch.tensor(test_real))\n",
    "        acc = correct / len(test_loader.dataset)\n",
    "        valid_loss /= len(test_loader)\n",
    "        f1score = f1_score(test_real, test_pred, average=weightedType)            \n",
    "\n",
    "        print(f\"(Test) Loss: {round(valid_loss, 3)}, AUC: {round(float(auc),3)}, ACC: {round(acc,3)}, F1score: {round(f1score, 3)}\")\n",
    "        print(\"################################################################################################\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sleep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
