{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "sys.path.append(\"../src/Metamodel/\")\n",
    "\n",
    "from utils.utils import EarlyStopping\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from data.dataloader import create_train_val_loader\n",
    "\n",
    "from models.depthwiseNet import DepthNet\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, auc, roc_auc_score, f1_score, classification_report\n",
    "from torchmetrics.classification import MulticlassAUROC\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "import random\n",
    "\n",
    "# from pytorchtools import EarlyStopping\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "np.random.seed(0)\n",
    "cudnn.benchmark = False\n",
    "cudnn.deterministic = True\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.cuda.manual_seed_all(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize seed if specified (might slow down the model)\n",
    "seed = 0 # Client 9\n",
    "# num = list(range(10,30))\n",
    "num = 6\n",
    "torch.manual_seed(seed)\n",
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device: \", device)\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 256\n",
    "database = \"../data/new\"\n",
    "weightedType = \"macro\"\n",
    "\n",
    "# Create the training, validation and test dataloader\n",
    "#\n",
    "train_set, validation_set = create_train_val_loader(database, batch_size, length=30,\n",
    "                                                    meta_train_client_idx_lst=[num], FLtrain=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(patience=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if type(num) == list:\n",
    "    train = train_set\n",
    "else:\n",
    "    train, test = torch.utils.data.random_split(train_set, [int(len(train_set)*0.8), len(train_set)-int(len(train_set)*0.8)], generator=torch.Generator().manual_seed(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if type(num) == list:\n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = torch.utils.data.DataLoader(validation_set, batch_size=batch_size, shuffle=False)\n",
    "else:\n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "    valid_loader = torch.utils.data.DataLoader(validation_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DepthNet(lengths=30, patch_size=30, in_chans=2, embed_dim=256, norm_layer=None, output_dim=3).to(device)\n",
    "\n",
    "lr = 0.0001\n",
    "optimizer_outer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer=optimizer_outer, step_size=40, gamma=0.5, last_epoch=-1, verbose=False)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "best_acc = 0\n",
    "best_f1 = 0\n",
    "best_auc = 0\n",
    "auroc = MulticlassAUROC(num_classes=3, average=weightedType).to(device)\n",
    "\n",
    "finish = False\n",
    "early_epoch = 1\n",
    "train_result_dic = {\"loss\": [], \"acc\": [], \"f1\": [], \"auc\": [], \"confusion_matrix\": []}\n",
    "test_result_dic = {\"loss\": [], \"acc\": [], \"f1\": [], \"auc\": [], \"confusion_matrix\": []}\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch += 1\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "\n",
    "    train_pred = []\n",
    "    train_real = []\n",
    "    train_proba = []\n",
    "    \n",
    "    for data in train_loader:            \n",
    "        x_data, stage = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        pred_value, _ = model(x_data)\n",
    "        pred = torch.argmax(pred_value, dim=1)\n",
    "        pred_proba = torch.sigmoid(pred_value)\n",
    "\n",
    "        correct += torch.sum(pred==stage).item()\n",
    "\n",
    "        train_pred.extend(pred.detach().cpu().numpy())\n",
    "        train_real.extend(stage.detach().cpu().numpy())\n",
    "        train_proba.extend(pred_proba.detach().cpu().numpy())\n",
    "\n",
    "        loss = criterion(pred_value, stage)\n",
    "\n",
    "        optimizer_outer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_outer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    auc = auroc(torch.tensor(train_proba), torch.tensor(train_real))\n",
    "    acc = correct / len(train_loader.dataset)\n",
    "    running_loss /= len(train_loader)\n",
    "    f1score = f1_score(train_real, train_pred, average=weightedType)\n",
    "\n",
    "    scheduler.step()\n",
    "    \n",
    "    print(f\"(Train) Epoch: {epoch}, Loss: {round(running_loss, 3)}, AUC: {round(float(auc),3)}, ACC: {round(acc,3)}, F1score: {round(f1score, 3)}\")\n",
    "\n",
    "    train_result_dic[\"loss\"].append(running_loss)\n",
    "    train_result_dic[\"acc\"].append(acc)\n",
    "    train_result_dic[\"f1\"].append(f1score)\n",
    "    train_result_dic[\"auc\"].append(auc.numpy())\n",
    "    train_result_dic[\"confusion_matrix\"].append(confusion_matrix(train_pred, train_real))\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        print(\"<< Validation >>\")\n",
    "\n",
    "        correct = 0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        model.eval()\n",
    "\n",
    "        val_pred = []\n",
    "        val_real = []\n",
    "        val_proba = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in valid_loader:\n",
    "                x_data, stage = data[0].to(device), data[1].to(device)\n",
    "                \n",
    "                # pred_value, _ = model(x_data)\n",
    "                pred_value, _ = model(x_data)\n",
    "                pred = torch.argmax(pred_value, dim=1)\n",
    "                pred_proba = torch.sigmoid(pred_value)\n",
    "\n",
    "                correct += torch.sum(pred==stage).item()\n",
    "\n",
    "                val_pred.extend(pred.detach().cpu().numpy())\n",
    "                val_real.extend(stage.detach().cpu().numpy())\n",
    "                val_proba.extend(pred_proba.detach().cpu().numpy())\n",
    "\n",
    "                loss = criterion(pred_value, stage)\n",
    "                valid_loss += loss.item()\n",
    "            \n",
    "            auc = auroc(torch.tensor(val_proba), torch.tensor(val_real))\n",
    "            acc = correct / len(valid_loader.dataset)\n",
    "            valid_loss /= len(valid_loader)\n",
    "            f1score = f1_score(val_real, val_pred, average=weightedType)            \n",
    "                \n",
    "            if best_f1 < f1score:\n",
    "                best_f1 = f1score\n",
    "                best_epoch = epoch\n",
    "\n",
    "                if type(num) == list:\n",
    "                    # torch.save(model.state_dict(), f\"../singlelog/total_3class.pt\")\n",
    "                    pass\n",
    "                else:\n",
    "                    # torch.save(model.state_dict(), f\"../singlelog/c{num}_3class.pt\")\n",
    "                    pass\n",
    "\n",
    "            print(\"################################################################################################\")\n",
    "            print(f\"(Valid) Epoch: {epoch}, Loss: {round(valid_loss, 3)}, AUC: {round(float(auc),3)}, ACC: {round(acc,3)}, F1score: {round(f1score, 3)}\")\n",
    "            print(\"################################################################################################\")\n",
    "\n",
    "\n",
    "            test_result_dic[\"loss\"].append(valid_loss)\n",
    "            test_result_dic[\"acc\"].append(acc)\n",
    "            test_result_dic[\"f1\"].append(f1score)\n",
    "            test_result_dic[\"auc\"].append(auc.numpy())\n",
    "            test_result_dic[\"confusion_matrix\"].append(confusion_matrix(val_pred, val_real))\n",
    "\n",
    "            # sns.heatmap(confusion_matrix(val_real, val_pred), annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "            # plt.title(f\"confusion_matrix (client {num})\")\n",
    "            # plt.xlabel(\"Predicted\")\n",
    "            # plt.ylabel(\"True\")\n",
    "            # plt.show()\n",
    "        \n",
    "    early_stop.step(f1score)\n",
    "    \n",
    "    if early_stop.is_stop():\n",
    "        print(\"Early Stopping in Epoch\", epoch)\n",
    "        if type(num) == list:\n",
    "            if finish != True:\n",
    "                # torch.save(model.state_dict(), f\"../singlelog/total_3class_earlystop{epoch}.pt\")\n",
    "                early_epoch = epoch\n",
    "                finish=True\n",
    "        else:\n",
    "            if finish != True:\n",
    "                # torch.save(model.state_dict(), f\"../singlelog/c{num}_3class_earlystop{epoch}.pt\")\n",
    "                finish=True\n",
    "                early_epoch = epoch\n",
    "        # break\n",
    "print(\"Best f1: \", best_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 1, figsize=(6, 8))\n",
    "\n",
    "learning_curve_1 = train_result_dic[\"loss\"]\n",
    "auc_curve_1 = train_result_dic[\"auc\"]\n",
    "f1_curve_1 = train_result_dic[\"f1\"]\n",
    "acc_curve_1 = train_result_dic[\"acc\"]\n",
    "\n",
    "learning_curve_2 = test_result_dic[\"loss\"]\n",
    "auc_curve_2 = test_result_dic[\"auc\"]\n",
    "f1_curve_2 = test_result_dic[\"f1\"]\n",
    "acc_curve_2 = test_result_dic[\"acc\"]\n",
    "\n",
    "axs[0].plot(learning_curve_1, label=\"Train\")\n",
    "axs[0].plot(learning_curve_2, label=\"Validation\")\n",
    "\n",
    "axs[3].plot(auc_curve_1, label=\"Train\")\n",
    "axs[3].plot(auc_curve_2, label=\"Validation\")\n",
    "\n",
    "axs[2].plot(f1_curve_1, label=\"Train\")\n",
    "axs[2].plot(f1_curve_2, label=\"Validation\")\n",
    "\n",
    "axs[1].plot(acc_curve_1, label=\"Train\")\n",
    "axs[1].plot(acc_curve_2, label=\"Validation\")\n",
    "\n",
    "\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[1].set_ylabel(\"Accuracy\")\n",
    "axs[2].set_ylabel(\"F1 score\")\n",
    "axs[3].set_ylabel(\"AUC\")\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "if type(num) == list:\n",
    "    plt.suptitle(f\"Independent Learning Curve\")\n",
    "else:\n",
    "    plt.suptitle(f\"Client {num} Learning Curve\")\n",
    "\n",
    "plt.legend(loc=(0.6, -0.5), ncol=2)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if type(num) == list:\n",
    "    bestmodel = torch.load(f\"../singlelog/total_3class.pt\")\n",
    "    # bestmodel = torch.load(f\"../singlelog/total_3class_earlystop{best_epoch}.pt\")\n",
    "else:\n",
    "    bestmodel = torch.load(f\"../singlelog/c{num}_3class.pt\")\n",
    "    # bestmodel = torch.load(f\"../singlelog/c{num}_3class_earlystop{early_epoch}.pt\")\n",
    "model.load_state_dict(bestmodel)\n",
    "\n",
    "\n",
    "test_pred = []\n",
    "test_real = []\n",
    "test_proba = []\n",
    "\n",
    "correct = 0\n",
    "\n",
    "test_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    for data in test_loader:\n",
    "        x_data, stage = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        # pred_value, _ = model(x_data)\n",
    "        pred_value, _ = model(x_data)\n",
    "        pred = torch.argmax(pred_value, dim=1)\n",
    "        pred_proba = torch.sigmoid(pred_value)\n",
    "\n",
    "        correct += torch.sum(pred==stage).item()\n",
    "\n",
    "        test_pred.extend(pred.detach().cpu().numpy())\n",
    "        test_real.extend(stage.detach().cpu().numpy())\n",
    "        test_proba.extend(pred_proba.detach().cpu().numpy())\n",
    "\n",
    "        loss = criterion(pred_value, stage)\n",
    "        test_loss += loss.item()\n",
    "    \n",
    "    auc = auroc(torch.tensor(test_proba), torch.tensor(test_real))\n",
    "    acc = correct / len(test_loader.dataset)\n",
    "    valid_loss /= len(test_loader)\n",
    "    f1score = f1_score(test_real, test_pred, average=weightedType)            \n",
    "\n",
    "    print(\"################################################################################################\")\n",
    "    print(f\"(Test) Loss: {round(valid_loss, 3)}, AUC: {round(float(auc),3)}, ACC: {round(acc,3)}, F1score: {round(f1score, 3)}\")\n",
    "    print(\"################################################################################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(test_real, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_confusion_matrix = confusion_matrix(test_pred, test_real)\n",
    "pcm = plt.imshow(_confusion_matrix, cmap='viridis', vmin=0, vmax=100)\n",
    "plt.title(f\"Client {num} Confusion Matrix\")\n",
    "plt.colorbar(pcm)\n",
    "    \n",
    "plt.xticks(np.arange(3), [\"wake\", \"NREM\", \"REM\"])\n",
    "plt.yticks(np.arange(3), [\"wake\", \"NREM\", \"REM\"])\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "    \n",
    "for t_i in range(3):\n",
    "    for t_j in range(3):\n",
    "        plt.text(t_i, t_j, f\"{_confusion_matrix[t_i][t_j]}\",\n",
    "                horizontalalignment=\"center\",\n",
    "                color=\"black\" if ((t_i == 1) and (t_j ==1)) else \"white\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sleep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
